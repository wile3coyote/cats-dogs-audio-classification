{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Opu1yz1lW9Os"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the required folders\n",
    "try:\n",
    "    os.makedirs(\"image/train/cat\")\n",
    "    os.makedirs(\"image/train/dog\")\n",
    "    os.makedirs(\"image/test/cat\")\n",
    "    os.makedirs(\"image/test/dog\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cojjta49XRoF"
   },
   "outputs": [],
   "source": [
    "#Function for creating the spectrogram of the audio from train dataset\n",
    "def create_spectrogram(filename,name,folder):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load('cats_dogs/train/'+folder+'/'+filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = 'image/train/'+ folder +'/' + name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ui3IFwHXs86"
   },
   "outputs": [],
   "source": [
    "#Fucntion for creating the spectrogram of the audio from test dataset\n",
    "def create_spectrogram_test(filename,name,folder):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load('cats_dogs/test/'+folder+'/'+filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = 'image/test/'+ folder +'/' + name + '.jpg'\n",
    "    fig.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yqwdUOXjX0Eb",
    "outputId": "7bfc1186-34ae-4b8b-a9e5-91b32c62f931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image  0 created\n",
      "image  1 created\n",
      "image  2 created\n",
      "image  3 created\n",
      "image  4 created\n",
      "image  5 created\n",
      "image  6 created\n",
      "image  7 created\n",
      "image  8 created\n",
      "image  9 created\n",
      "image  10 created\n",
      "image  11 created\n",
      "image  12 created\n",
      "image  13 created\n",
      "image  14 created\n",
      "image  15 created\n",
      "image  16 created\n",
      "image  17 created\n",
      "image  18 created\n",
      "image  19 created\n",
      "image  20 created\n",
      "image  21 created\n",
      "image  22 created\n",
      "image  23 created\n",
      "image  24 created\n",
      "image  25 created\n",
      "image  26 created\n",
      "image  27 created\n",
      "image  28 created\n",
      "image  29 created\n",
      "image  30 created\n",
      "image  31 created\n",
      "image  32 created\n",
      "image  33 created\n",
      "image  34 created\n",
      "image  35 created\n",
      "image  36 created\n",
      "image  37 created\n",
      "image  38 created\n",
      "image  39 created\n",
      "image  40 created\n",
      "image  41 created\n",
      "image  42 created\n",
      "image  43 created\n",
      "image  44 created\n",
      "image  45 created\n",
      "image  46 created\n",
      "image  47 created\n",
      "image  48 created\n",
      "image  49 created\n",
      "image  50 created\n",
      "image  51 created\n",
      "image  52 created\n",
      "image  53 created\n",
      "image  54 created\n",
      "image  55 created\n",
      "image  56 created\n",
      "image  57 created\n",
      "image  58 created\n",
      "image  59 created\n",
      "image  60 created\n",
      "image  61 created\n",
      "image  62 created\n",
      "image  63 created\n",
      "image  64 created\n",
      "image  65 created\n",
      "image  66 created\n",
      "image  67 created\n",
      "image  68 created\n",
      "image  69 created\n",
      "image  70 created\n",
      "image  71 created\n",
      "image  72 created\n",
      "image  73 created\n",
      "image  74 created\n",
      "image  75 created\n",
      "image  76 created\n",
      "image  77 created\n",
      "image  78 created\n",
      "image  79 created\n",
      "image  80 created\n",
      "image  81 created\n",
      "image  82 created\n",
      "image  83 created\n",
      "image  84 created\n",
      "image  85 created\n",
      "image  86 created\n",
      "image  87 created\n",
      "image  88 created\n",
      "image  89 created\n",
      "image  90 created\n",
      "image  91 created\n",
      "image  92 created\n",
      "image  93 created\n",
      "image  94 created\n",
      "image  95 created\n",
      "image  96 created\n",
      "image  97 created\n",
      "image  98 created\n",
      "image  99 created\n",
      "image  100 created\n",
      "image  101 created\n",
      "image  102 created\n",
      "image  103 created\n",
      "image  104 created\n",
      "image  105 created\n",
      "image  106 created\n",
      "image  107 created\n",
      "image  108 created\n",
      "image  109 created\n",
      "image  110 created\n",
      "image  111 created\n",
      "image  112 created\n",
      "image  113 created\n",
      "image  114 created\n",
      "image  115 created\n",
      "image  116 created\n",
      "image  117 created\n",
      "image  118 created\n",
      "image  119 created\n",
      "image  120 created\n",
      "image  121 created\n",
      "image  122 created\n",
      "image  123 created\n",
      "image  124 created\n",
      "image  125 created\n",
      "image  126 created\n",
      "image  127 created\n",
      "image  128 created\n",
      "image  129 created\n",
      "image  130 created\n",
      "image  131 created\n",
      "image  132 created\n",
      "image  133 created\n",
      "image  134 created\n",
      "image  135 created\n",
      "image  136 created\n",
      "image  137 created\n",
      "image  138 created\n",
      "image  139 created\n",
      "image  140 created\n",
      "image  141 created\n",
      "image  142 created\n",
      "image  143 created\n",
      "image  144 created\n",
      "image  145 created\n",
      "image  146 created\n",
      "image  147 created\n",
      "image  148 created\n",
      "image  149 created\n",
      "image  150 created\n",
      "image  151 created\n",
      "image  152 created\n",
      "image  153 created\n",
      "image  154 created\n",
      "image  155 created\n",
      "image  156 created\n",
      "image  157 created\n",
      "image  158 created\n",
      "image  159 created\n",
      "image  160 created\n",
      "image  161 created\n",
      "image  162 created\n",
      "image  163 created\n",
      "image  164 created\n",
      "image  165 created\n",
      "image  166 created\n",
      "image  167 created\n",
      "image  168 created\n",
      "image  169 created\n",
      "image  170 created\n",
      "image  171 created\n",
      "image  172 created\n",
      "image  173 created\n",
      "image  174 created\n",
      "image  175 created\n",
      "image  176 created\n",
      "image  177 created\n",
      "image  178 created\n",
      "image  179 created\n",
      "image  180 created\n",
      "image  181 created\n",
      "image  182 created\n",
      "image  183 created\n",
      "image  184 created\n",
      "image  185 created\n",
      "image  186 created\n",
      "image  187 created\n",
      "image  188 created\n",
      "image  189 created\n",
      "image  190 created\n",
      "image  191 created\n",
      "image  192 created\n",
      "image  193 created\n",
      "image  194 created\n",
      "image  195 created\n",
      "image  196 created\n",
      "image  197 created\n",
      "image  198 created\n",
      "image  199 created\n",
      "image  200 created\n",
      "image  201 created\n",
      "image  202 created\n",
      "image  203 created\n",
      "image  204 created\n",
      "image  205 created\n",
      "image  206 created\n",
      "image  207 created\n",
      "image  208 created\n",
      "image  209 created\n"
     ]
    }
   ],
   "source": [
    "#Creating the spectrogram of the train split\n",
    "\n",
    "a=0\n",
    "for subdir in os.listdir('cats_dogs/train'):\n",
    "  for filename in os.listdir('cats_dogs/train/'+subdir):\n",
    "    filename,name = filename,filename.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram(filename,name,subdir)\n",
    "    print(\"Image\",a,'created')\n",
    "    a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SP7zP7QMYPII",
    "outputId": "8418d30f-0ed1-4281-e7cb-f1c4493aefb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 created\n",
      "Image 1 created\n",
      "Image 2 created\n",
      "Image 3 created\n",
      "Image 4 created\n",
      "Image 5 created\n",
      "Image 6 created\n",
      "Image 7 created\n",
      "Image 8 created\n",
      "Image 9 created\n",
      "Image 10 created\n",
      "Image 11 created\n",
      "Image 12 created\n",
      "Image 13 created\n",
      "Image 14 created\n",
      "Image 15 created\n",
      "Image 16 created\n",
      "Image 17 created\n",
      "Image 18 created\n",
      "Image 19 created\n",
      "Image 20 created\n",
      "Image 21 created\n",
      "Image 22 created\n",
      "Image 23 created\n",
      "Image 24 created\n",
      "Image 25 created\n",
      "Image 26 created\n",
      "Image 27 created\n",
      "Image 28 created\n",
      "Image 29 created\n",
      "Image 30 created\n",
      "Image 31 created\n",
      "Image 32 created\n",
      "Image 33 created\n",
      "Image 34 created\n",
      "Image 35 created\n",
      "Image 36 created\n",
      "Image 37 created\n",
      "Image 38 created\n",
      "Image 39 created\n",
      "Image 40 created\n",
      "Image 41 created\n",
      "Image 42 created\n",
      "Image 43 created\n",
      "Image 44 created\n",
      "Image 45 created\n",
      "Image 46 created\n",
      "Image 47 created\n",
      "Image 48 created\n",
      "Image 49 created\n",
      "Image 50 created\n",
      "Image 51 created\n",
      "Image 52 created\n",
      "Image 53 created\n",
      "Image 54 created\n",
      "Image 55 created\n",
      "Image 56 created\n",
      "Image 57 created\n",
      "Image 58 created\n",
      "Image 59 created\n",
      "Image 60 created\n",
      "Image 61 created\n",
      "Image 62 created\n",
      "Image 63 created\n",
      "Image 64 created\n",
      "Image 65 created\n",
      "Image 66 created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Renaming the test folders\n",
    "try:\n",
    "    os.rename('cats_dogs/test/cats','cats_dogs/test/cat')\n",
    "    os.rename('cats_dogs/test/test','cats_dogs/test/dog')\n",
    "except FileNotFoundError:\n",
    "    # directory name already changed\n",
    "    pass\n",
    "a=0\n",
    "for subdir in os.listdir('cats_dogs/test'):\n",
    "  for filename in os.listdir('cats_dogs/test/'+subdir):\n",
    "    filename,name = filename,filename.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram_test(filename,name,subdir)\n",
    "    print(\"Image\",a,'created')\n",
    "    a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "pKmiigNTY3WB",
    "outputId": "6e0c9e0a-d7f7-4670-eb94-33a7a49ad643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 2 classes.\n",
      "Found 67 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=training_datagen.flow_from_directory(\n",
    "    directory='image/train',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=37,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "    directory='image/test',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=37,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjPoBIJIaAtY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Flatten,Dropout,Conv2D, MaxPooling2D,Activation,LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(128,128,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eApqFH9xaGvk"
   },
   "outputs": [],
   "source": [
    "#Callback fucntion to stop training when validation accuracy  reaches 95%\n",
    "class myCallback(Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_acc')>0.95):\n",
    "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "model.compile(optimizers.Adam(lr=1e-4, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7fx8Izs8aO0I",
    "outputId": "a69c80a4-1eb7-4d91-8c1a-ab91d812f007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 177ms/step - loss: 0.1983 - acc: 0.9326 - val_loss: 0.2776 - val_acc: 0.9062\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 0.1725 - acc: 0.9438 - val_loss: 0.2608 - val_acc: 0.9062\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 0.1761 - acc: 0.9531 - val_loss: 0.2548 - val_acc: 0.9375\n",
      "Epoch 4/50\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.1604 - acc: 0.9394\n",
      "Reached 95% accuracy so cancelling training!\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 0.1549 - acc: 0.9451 - val_loss: 0.2443 - val_acc: 0.9531\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "callbacks = myCallback()\n",
    "\n",
    "History=model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=50,\n",
    "                    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvJy9wtGaTi4"
   },
   "outputs": [],
   "source": [
    "#Function for creating spectrogram for the input audio to be predicted\n",
    "def create_spectrogram_pred(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  =  name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0zHRrbMb_bx"
   },
   "outputs": [],
   "source": [
    "#Function for predicting cat or dog of the input audio\n",
    "def pred_sound(filename):\n",
    "  filename,name = filename,filename.split('/')[-1].split('.')[0]\n",
    "  create_spectrogram_pred(filename,name)\n",
    "  img = Image.open(name+'.jpg')\n",
    "  img = img.resize((128,128))\n",
    "  sample=np.expand_dims(img,axis=0)\n",
    "  y_hat=model.predict(sample)\n",
    "  if np.argmax(y_hat[0])==0:\n",
    "    print(\"The audio is by cat\")\n",
    "  else:\n",
    "    print(\"The audio is by dog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qCau5dJCc-LK",
    "outputId": "5be503c5-b930-41b3-9fa7-2f34ebe54854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The audio is by dog\n"
     ]
    }
   ],
   "source": [
    "pred_sound('bark.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cats and Dogs classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
